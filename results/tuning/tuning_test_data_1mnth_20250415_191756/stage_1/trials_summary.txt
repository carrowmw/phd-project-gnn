# Hyperparameter Tuning Report: tuning_test_data_1mnth_20250415_191756_stage_1

Total trials: 15
Completed trials: 15
Best trial: #7
Best value: 0.6446069478988647

## Best Parameters

+------------------------+---------------+
| Parameter              |         Value |
+========================+===============+
| model.hidden_dim       | 128           |
+------------------------+---------------+
| model.num_layers       |   3           |
+------------------------+---------------+
| model.num_gc_layers    |   1           |
+------------------------+---------------+
| model.dropout          |   0.494755    |
+------------------------+---------------+
| training.learning_rate |   0.0035034   |
+------------------------+---------------+
| training.weight_decay  |   3.94591e-06 |
+------------------------+---------------+

## Top 10 Trials

+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|   number |    value |   model.hidden_dim |   model.num_layers |   model.num_gc_layers |   model.dropout |   training.learning_rate |   training.weight_decay |   duration_seconds |
+==========+==========+====================+====================+=======================+=================+==========================+=========================+====================+
|        7 | 0.644607 |                128 |                  3 |                     1 |        0.494755 |               0.0035034  |             3.94591e-06 |           2133.03  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|       11 | 0.646387 |                128 |                  2 |                     2 |        0.320686 |               0.00205701 |             2.49498e-06 |           1535.1   |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|       13 | 0.647197 |                128 |                  2 |                     3 |        0.416334 |               0.00243251 |             6.61459e-06 |           1585.08  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        2 | 0.648703 |                128 |                  1 |                     2 |        0.282428 |               0.00371836 |             3.97211e-06 |           1785.14  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|       10 | 0.648948 |                256 |                  3 |                     2 |        0.481998 |               0.00190624 |             1.3067e-06  |           2243.45  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|       14 | 0.6495   |                128 |                  3 |                     2 |        0.321266 |               0.00084782 |             2.72112e-06 |           2198.81  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|       12 | 0.652489 |                128 |                  2 |                     2 |        0.39129  |               0.00163821 |             1.04648e-06 |           1078.06  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        9 | 0.653278 |                 32 |                  1 |                     3 |        0.355023 |               0.00594875 |             2.61003e-05 |            674.727 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        0 | 0.655206 |                 64 |                  1 |                     1 |        0.123233 |               0.00539948 |             6.35836e-05 |            735.598 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        5 | 0.655552 |                 32 |                  1 |                     3 |        0.410053 |               0.00756829 |             0.000483595 |            835.798 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+

## Parameter Importance

+------------------------+--------------+
| Parameter              |   Importance |
+========================+==============+
| training.weight_decay  |    0.245708  |
+------------------------+--------------+
| training.learning_rate |    0.188833  |
+------------------------+--------------+
| model.hidden_dim       |    0.168258  |
+------------------------+--------------+
| model.num_gc_layers    |    0.162865  |
+------------------------+--------------+
| model.dropout          |    0.144796  |
+------------------------+--------------+
| model.num_layers       |    0.0895395 |
+------------------------+--------------+