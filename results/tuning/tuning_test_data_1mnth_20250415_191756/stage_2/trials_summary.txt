# Hyperparameter Tuning Report: tuning_test_data_1mnth_20250415_191756_stage_2

Total trials: 10
Completed trials: 10
Best trial: #3
Best value: 0.6373923603031371

## Best Parameters

+------------------------+---------------+
| Parameter              |         Value |
+========================+===============+
| model.hidden_dim       | 128           |
+------------------------+---------------+
| model.num_layers       |   3           |
+------------------------+---------------+
| model.num_gc_layers    |   2           |
+------------------------+---------------+
| model.dropout          |   0.404045    |
+------------------------+---------------+
| training.learning_rate |   0.00443724  |
+------------------------+---------------+
| training.weight_decay  |   1.36634e-06 |
+------------------------+---------------+

## Top 10 Trials

+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|   number |    value |   model.hidden_dim |   model.num_layers |   model.num_gc_layers |   model.dropout |   training.learning_rate |   training.weight_decay |   duration_seconds |
+==========+==========+====================+====================+=======================+=================+==========================+=========================+====================+
|        3 | 0.637392 |                128 |                  3 |                     2 |        0.404045 |               0.00443724 |             1.36634e-06 |            4403.19 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        5 | 0.640269 |                128 |                  4 |                     1 |        0.527259 |               0.00231641 |             4.20921e-06 |            5761    |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        2 | 0.642863 |                128 |                  2 |                     2 |        0.422654 |               0.00221894 |             2.56643e-06 |            2153.75 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        0 | 0.647975 |                128 |                  3 |                     1 |        0.425954 |               0.00132677 |             1.28245e-05 |            2642.68 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        1 | 0.650253 |                128 |                  4 |                     2 |        0.437223 |               0.0017413  |             1.42418e-06 |            2860.6  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        8 | 0.652344 |                128 |                  4 |                     1 |        0.592132 |               0.00637202 |             1.49613e-06 |            3474.29 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        6 | 0.654606 |                256 |                  4 |                     2 |        0.57372  |               0.0043442  |             1.53427e-05 |            3530.22 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        4 | 0.656098 |                256 |                  4 |                     1 |        0.414289 |               0.00525161 |             3.2545e-06  |            2358.97 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        7 | 0.658919 |                128 |                  2 |                     1 |        0.449025 |               0.00721414 |             2.48827e-06 |            1255.36 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        9 | 0.663876 |                128 |                  4 |                     2 |        0.409564 |               0.00256703 |             1.14592e-06 |            1769.39 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+

## Parameter Importance

+------------------------+--------------+
| Parameter              |   Importance |
+========================+==============+
| training.learning_rate |   0.46689    |
+------------------------+--------------+
| model.dropout          |   0.203045   |
+------------------------+--------------+
| training.weight_decay  |   0.126746   |
+------------------------+--------------+
| model.num_layers       |   0.097294   |
+------------------------+--------------+
| model.hidden_dim       |   0.0970641  |
+------------------------+--------------+
| model.num_gc_layers    |   0.00896122 |
+------------------------+--------------+