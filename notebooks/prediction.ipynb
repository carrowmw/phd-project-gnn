{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Prediction Workflow:\n",
    "\n",
    "1. Loads recent data from the API\n",
    "2. Performs minimal preprocessing (no complex splitting)\n",
    "3. Creates only a validation data loader\n",
    "4. Loads a pre-trained model\n",
    "5. Generates predictions\n",
    "6. Compares to actual values when available\n",
    "7. Returns formatted predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a notebook cell\n",
    "import asyncio\n",
    "from gnn_package import training\n",
    "from gnn_package.config import ExperimentConfig\n",
    "from gnn_package.src.utils.config_utils import create_prediction_config\n",
    "\n",
    "# For prediction\n",
    "prediction_config = create_prediction_config()\n",
    "\n",
    "predictions = await training.predict_all_sensors_with_validation(\n",
    "    model_path=\"stgnn_model_test_data_1wk.pth\",\n",
    "    config=prediction_config,\n",
    "    output_file=\"predictions.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a config and manually validate it\n",
    "try:\n",
    "    config = ExperimentConfig(\n",
    "        config_path=\"models/Default_Traffic_Prediction_Experiment/config.yml\"\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"Configuration validation failed: {e}\")\n",
    "    # Handle the error or fall back to defaults\n",
    "\n",
    "# Log the configuration with a custom logger\n",
    "import logging\n",
    "\n",
    "custom_logger = logging.getLogger(\"experiment_logger\")\n",
    "custom_logger.setLevel(logging.DEBUG)\n",
    "config.log(logger=custom_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = await training.predict_all_sensors_with_validation(\n",
    "    model_path=\"models/Default_Traffic_Prediction_Experiment/model.pth\",\n",
    "    config=config,\n",
    "    output_file=\"predictions.csv\",\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "if predictions:\n",
    "    df = predictions[\"dataframe\"]\n",
    "    print(f\"Generated {len(df)} predictions for {df['node_id'].nunique()} sensors\")\n",
    "\n",
    "    # Show prediction ranges\n",
    "    print(\"\\nPrediction summary stats:\")\n",
    "    print(df.groupby(\"horizon\")[\"prediction\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"dataframe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensors_grid(predictions_df, plots_per_row=5, figsize=(20, 25)):\n",
    "    \"\"\"\n",
    "    Create a grid of plots showing prediction vs actual values for all sensors.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions_df : pandas DataFrame\n",
    "        DataFrame containing the prediction results with columns:\n",
    "        'node_id', 'sensor_name', 'timestamp', 'prediction', 'actual', 'horizon'\n",
    "    plots_per_row : int\n",
    "        Number of plots to show in each row\n",
    "    figsize : tuple\n",
    "        Size of the overall figure (width, height)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "        The figure containing the grid of plots\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from matplotlib.dates import DateFormatter\n",
    "\n",
    "    # Get unique sensors\n",
    "    unique_sensors = predictions_df[\"node_id\"].unique()\n",
    "    num_sensors = len(unique_sensors)\n",
    "\n",
    "    # Calculate grid dimensions\n",
    "    num_rows = int(np.ceil(num_sensors / plots_per_row))\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig, axes = plt.subplots(num_rows, plots_per_row, figsize=figsize)\n",
    "    axes = axes.flatten()  # Flatten to make indexing easier\n",
    "\n",
    "    # Set overall title\n",
    "    fig.suptitle(f\"Predictions vs Actual Values for {num_sensors} Sensors\", fontsize=16)\n",
    "\n",
    "    # Format for dates\n",
    "    date_formatter = DateFormatter(\"%H:%M\")\n",
    "\n",
    "    # Loop through each sensor and create a plot\n",
    "    for i, sensor_id in enumerate(unique_sensors):\n",
    "        if i >= len(axes):  # Safety check\n",
    "            break\n",
    "\n",
    "        # Get data for this sensor\n",
    "        sensor_data = predictions_df[predictions_df[\"node_id\"] == sensor_id]\n",
    "\n",
    "        # Check if we have data\n",
    "        if len(sensor_data) > 0:\n",
    "            # Get sensor name\n",
    "            sensor_name = sensor_data[\"sensor_name\"].iloc[0]\n",
    "\n",
    "            # Sort by timestamp to ensure correct plot order\n",
    "            sensor_data = sensor_data.sort_values(\"timestamp\")\n",
    "\n",
    "            # Get x and y values\n",
    "            timestamps = sensor_data[\"timestamp\"]\n",
    "            predictions = sensor_data[\"prediction\"]\n",
    "            actuals = sensor_data[\"actual\"]\n",
    "\n",
    "            # Plot\n",
    "            ax = axes[i]\n",
    "            ax.plot(timestamps, predictions, \"r-\", label=\"Prediction\", linewidth=2)\n",
    "            ax.plot(timestamps, actuals, \"b-\", label=\"Actual\", linewidth=2)\n",
    "\n",
    "            # Format plot\n",
    "            ax.set_title(f\"{sensor_name.split('Ncl')[-1]}\", fontsize=10)\n",
    "            ax.tick_params(axis=\"x\", rotation=45, labelsize=8)\n",
    "            ax.tick_params(axis=\"y\", labelsize=8)\n",
    "            ax.xaxis.set_major_formatter(date_formatter)\n",
    "\n",
    "            # Only show legend for the first plot\n",
    "            if i == 0:\n",
    "                ax.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "            # Add grid for better readability\n",
    "            ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "            # Calculate and show error metrics\n",
    "            mse = ((predictions - actuals) ** 2).mean()\n",
    "            mae = (predictions - actuals).abs().mean()\n",
    "            ax.text(\n",
    "                0.02,\n",
    "                0.95,\n",
    "                f\"MAE: {mae:.1f}\",\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=7,\n",
    "                bbox=dict(facecolor=\"white\", alpha=0.7),\n",
    "            )\n",
    "        else:\n",
    "            # No data case\n",
    "            ax.text(\n",
    "                0.5,\n",
    "                0.5,\n",
    "                f\"No data for {sensor_id}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                transform=ax.transAxes,\n",
    "            )\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    # Turn off unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    # Adjust spacing\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])  # Make room for suptitle\n",
    "\n",
    "    # return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensors_grid(predictions[\"dataframe\"], plots_per_row=5, figsize=(20, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
