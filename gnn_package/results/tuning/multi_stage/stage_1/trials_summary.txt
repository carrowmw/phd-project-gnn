# Hyperparameter Tuning Report: tuning_test_data_1wk_20250423_184843_stage_1

Total trials: 15
Completed trials: 15
Best trial: #13
Best value: 1.0240411758422852

## Best Parameters

+------------------------+---------------+
| Parameter              |         Value |
+========================+===============+
| model.hidden_dim       | 128           |
+------------------------+---------------+
| model.num_layers       |   2           |
+------------------------+---------------+
| model.num_gc_layers    |   2           |
+------------------------+---------------+
| model.dropout          |   0.375815    |
+------------------------+---------------+
| training.learning_rate |   0.0019785   |
+------------------------+---------------+
| training.weight_decay  |   1.14865e-05 |
+------------------------+---------------+

## Top 10 Trials

+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|   number |   value |   model.hidden_dim |   model.num_layers |   model.num_gc_layers |   model.dropout |   training.learning_rate |   training.weight_decay |   duration_seconds |
+==========+=========+====================+====================+=======================+=================+==========================+=========================+====================+
|       13 | 1.02404 |                128 |                  2 |                     2 |        0.375815 |              0.0019785   |             1.14865e-05 |            365.606 |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        4 | 1.03103 |                128 |                  1 |                     2 |        0.113755 |              0.00658629  |             5.97503e-06 |            200.865 |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|       12 | 1.04475 |                128 |                  2 |                     2 |        0.316727 |              0.00239762  |             6.94708e-06 |            366.451 |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        2 | 1.04921 |                128 |                  1 |                     2 |        0.282428 |              0.00371836  |             3.97211e-06 |            198.486 |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|       11 | 1.05076 |                128 |                  2 |                     2 |        0.192601 |              0.00205344  |             6.6345e-06  |            372.527 |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|       10 | 1.06332 |                256 |                  2 |                     2 |        0.107185 |              0.00135278  |             1.3067e-06  |            375.363 |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        9 | 1.07872 |                 32 |                  1 |                     3 |        0.355023 |              0.00594875  |             2.61003e-05 |            200.98  |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        0 | 1.07944 |                 64 |                  1 |                     1 |        0.123233 |              0.00539948  |             6.35836e-05 |            159.345 |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        7 | 1.08089 |                128 |                  3 |                     1 |        0.494755 |              0.0035034   |             3.94591e-06 |            491.305 |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        1 | 1.08176 |                128 |                  1 |                     1 |        0.173362 |              0.000405961 |             3.75206e-05 |            176.845 |
+----------+---------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+

## Parameter Importance

+------------------------+--------------+
| Parameter              |   Importance |
+========================+==============+
| training.weight_decay  |    0.666181  |
+------------------------+--------------+
| model.hidden_dim       |    0.0910552 |
+------------------------+--------------+
| model.num_layers       |    0.0838933 |
+------------------------+--------------+
| model.num_gc_layers    |    0.0825969 |
+------------------------+--------------+
| model.dropout          |    0.0608314 |
+------------------------+--------------+
| training.learning_rate |    0.0154422 |
+------------------------+--------------+