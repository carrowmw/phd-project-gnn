# Hyperparameter Tuning Report: tuning_test_data_1wk_20250423_184843_stage_2

Total trials: 10
Completed trials: 10
Best trial: #9
Best value: 0.8842341552178065

## Best Parameters

+------------------------+---------------+
| Parameter              |         Value |
+========================+===============+
| model.hidden_dim       | 128           |
+------------------------+---------------+
| model.num_layers       |   3           |
+------------------------+---------------+
| model.num_gc_layers    |   3           |
+------------------------+---------------+
| model.dropout          |   0.290624    |
+------------------------+---------------+
| training.learning_rate |   0.0014497   |
+------------------------+---------------+
| training.weight_decay  |   3.33577e-06 |
+------------------------+---------------+

## Top 10 Trials

+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|   number |    value |   model.hidden_dim |   model.num_layers |   model.num_gc_layers |   model.dropout |   training.learning_rate |   training.weight_decay |   duration_seconds |
+==========+==========+====================+====================+=======================+=================+==========================+=========================+====================+
|        9 | 0.884234 |                128 |                  3 |                     3 |        0.290624 |              0.0014497   |             3.33577e-06 |          21282.3   |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        6 | 0.89319  |                256 |                  3 |                     3 |        0.45478  |              0.00245334  |             4.46625e-05 |           1127.66  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        1 | 0.918681 |                128 |                  3 |                     3 |        0.318282 |              0.000983378 |             4.14579e-06 |           1089.39  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        2 | 0.996109 |                128 |                  1 |                     2 |        0.303713 |              0.00125312  |             7.47085e-06 |            411.213 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        3 | 1.00802  |                128 |                  2 |                     2 |        0.285105 |              0.00250588  |             3.97741e-06 |            732.203 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        7 | 1.0204   |                128 |                  1 |                     2 |        0.330084 |              0.0040741   |             7.24333e-06 |           2116.77  |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        0 | 1.07708  |                128 |                  2 |                     1 |        0.307014 |              0.000749275 |             3.7332e-05  |            683.703 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        8 | 1.0784   |                128 |                  3 |                     1 |        0.473192 |              0.00359852  |             4.35523e-06 |          17160     |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        5 | 1.07918  |                128 |                  3 |                     1 |        0.408319 |              0.00130817  |             1.2253e-05  |            898.976 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+
|        4 | 1.07929  |                256 |                  3 |                     1 |        0.295349 |              0.00296578  |             9.47382e-06 |            570.243 |
+----------+----------+--------------------+--------------------+-----------------------+-----------------+--------------------------+-------------------------+--------------------+

## Parameter Importance

+------------------------+--------------+
| Parameter              |   Importance |
+========================+==============+
| model.num_gc_layers    |    0.748815  |
+------------------------+--------------+
| training.weight_decay  |    0.116764  |
+------------------------+--------------+
| training.learning_rate |    0.0664007 |
+------------------------+--------------+
| model.num_layers       |    0.025396  |
+------------------------+--------------+
| model.dropout          |    0.0244997 |
+------------------------+--------------+
| model.hidden_dim       |    0.0181238 |
+------------------------+--------------+