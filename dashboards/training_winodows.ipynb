{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "# from plotly.subplots import make_subplots\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Helper function to load data from file\n",
    "def load_data(file_path=\"test_data_1yr.pkl\"):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "# # Find continuous segments in time series\n",
    "# def find_continuous_segments(time_index, values, gap_threshold=pd.Timedelta(minutes=15)):\n",
    "#     segments = []\n",
    "#     start_idx = 0\n",
    "\n",
    "#     for i in range(1, len(time_index)):\n",
    "#         time_diff = time_index[i] - time_index[i-1]\n",
    "\n",
    "#         # Check for gaps in time or values\n",
    "#         if (time_diff > gap_threshold) or (np.isnan(values[i-1]) or np.isnan(values[i])):\n",
    "#             if i - start_idx >= 24:  # Assuming minimum window size of 24\n",
    "#                 segments.append((start_idx, i))\n",
    "#             start_idx = i\n",
    "\n",
    "#     # Add the last segment if it's long enough\n",
    "#     if len(time_index) - start_idx >= 24:\n",
    "#         segments.append((start_idx, len(time_index)))\n",
    "\n",
    "#     return segments\n",
    "\n",
    "# # Create an interactive data availability heatmap\n",
    "# def interactive_data_availability(time_series_dict):\n",
    "#     \"\"\"Create an interactive heatmap showing data availability across sensors over time\"\"\"\n",
    "#     # Get all unique timestamps from all sensors\n",
    "#     all_timestamps = set()\n",
    "#     for sensor_id, series in time_series_dict.items():\n",
    "#         all_timestamps.update(series.index)\n",
    "\n",
    "#     all_timestamps = sorted(all_timestamps)\n",
    "\n",
    "#     # Create a DataFrame with all timestamps and fill with NaN\n",
    "#     data_matrix = pd.DataFrame(index=all_timestamps)\n",
    "\n",
    "#     # For each sensor, add a column to the DataFrame\n",
    "#     for sensor_id, series in time_series_dict.items():\n",
    "#         data_matrix[sensor_id] = np.nan\n",
    "#         # Only fill in data that exists\n",
    "#         data_matrix.loc[series.index, sensor_id] = 1\n",
    "\n",
    "#     # Resample to a lower resolution for better visualization if too many datapoints\n",
    "#     if len(all_timestamps) > 1000:\n",
    "#         data_matrix = data_matrix.resample('1H').mean()\n",
    "\n",
    "#     # Convert to long format for plotly\n",
    "#     data_long = data_matrix.reset_index().melt(\n",
    "#         id_vars='index',\n",
    "#         var_name='sensor_id',\n",
    "#         value_name='has_data'\n",
    "#     )\n",
    "\n",
    "#     # Create the heatmap with plotly\n",
    "#     fig = px.density_heatmap(\n",
    "#         data_long,\n",
    "#         x='index',\n",
    "#         y='sensor_id',\n",
    "#         z='has_data',\n",
    "#         color_continuous_scale=[\n",
    "#             [0, 'rgba(255,255,255,0)'],  # Transparent for NaN\n",
    "#             [0.5, 'rgba(222,235,247,1)'],  # Light blue\n",
    "#             [1, 'rgba(49,130,189,1)']      # Dark blue\n",
    "#         ],\n",
    "#         title='Data Availability Across Sensors (Interactive)',\n",
    "#         labels={'index': 'Date', 'sensor_id': 'Sensor ID', 'has_data': 'Data Available'}\n",
    "#     )\n",
    "\n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         height=800,\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Sensor ID',\n",
    "#         title_x=0.5,\n",
    "#         coloraxis_showscale=False\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create interactive window visualization for a given sensor\n",
    "# def interactive_sensor_windows(time_series_dict, sensor_id, window_size=24, stride=1):\n",
    "#     \"\"\"Create an interactive visualization of windows for a specific sensor\"\"\"\n",
    "#     series = time_series_dict.get(sensor_id)\n",
    "#     if series is None or len(series) == 0:\n",
    "#         return None\n",
    "\n",
    "#     # Find continuous segments\n",
    "#     segments = find_continuous_segments(series.index, series.values)\n",
    "\n",
    "#     # Create a figure\n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     # Add the raw time series\n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         x=series.index,\n",
    "#         y=series.values,\n",
    "#         mode='lines',\n",
    "#         name='Raw Data',\n",
    "#         line=dict(color='darkgray')\n",
    "#     ))\n",
    "\n",
    "#     # Add segments and windows\n",
    "#     for start_seg, end_seg in segments:\n",
    "#         segment_indices = series.index[start_seg:end_seg]\n",
    "\n",
    "#         # Add segment highlight\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             x=[segment_indices[0], segment_indices[0], segment_indices[-1], segment_indices[-1]],\n",
    "#             y=[series.values.min(), series.values.max(), series.values.max(), series.values.min()],\n",
    "#             fill=\"toself\",\n",
    "#             mode='none',\n",
    "#             name=f'Segment: {segment_indices[0].date()} to {segment_indices[-1].date()}',\n",
    "#             fillcolor='rgba(144,238,144,0.2)',\n",
    "#             showlegend=True\n",
    "#         ))\n",
    "\n",
    "#         # Add a few example windows\n",
    "#         n_windows = len(segment_indices) - window_size + 1\n",
    "\n",
    "#         # Only show a few windows to avoid overcrowding\n",
    "#         window_step = max(1, n_windows // 5)\n",
    "\n",
    "#         for i in range(0, n_windows, window_step):\n",
    "#             window_start = segment_indices[i]\n",
    "#             window_end = segment_indices[i + window_size - 1]\n",
    "\n",
    "#             fig.add_trace(go.Scatter(\n",
    "#                 x=[window_start, window_start, window_end, window_end],\n",
    "#                 y=[series.values.min(), series.values.max(), series.values.max(), series.values.min()],\n",
    "#                 fill=\"toself\",\n",
    "#                 mode='none',\n",
    "#                 name=f'Window: {window_start}',\n",
    "#                 fillcolor='rgba(0,0,255,0.1)',\n",
    "#                 showlegend=False\n",
    "#             ))\n",
    "\n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         title=f'Time Windows for Sensor {sensor_id}',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Traffic Count',\n",
    "#         height=600,\n",
    "#         legend=dict(\n",
    "#             orientation=\"h\",\n",
    "#             yanchor=\"bottom\",\n",
    "#             y=1.02,\n",
    "#             xanchor=\"right\",\n",
    "#             x=1\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create a dashboard with multiple sensor window visualizations\n",
    "# def interactive_window_dashboard(time_series_dict, window_size=24, n_sensors=4):\n",
    "#     \"\"\"Create a dashboard with window visualizations for multiple sensors\"\"\"\n",
    "#     # Identify sensors with most data points\n",
    "#     sensor_data_counts = {sensor_id: len(series) for sensor_id, series in time_series_dict.items()}\n",
    "#     top_sensors = sorted(sensor_data_counts, key=sensor_data_counts.get, reverse=True)[:n_sensors]\n",
    "\n",
    "#     # Create subplots\n",
    "#     fig = make_subplots(\n",
    "#         rows=n_sensors,\n",
    "#         cols=1,\n",
    "#         subplot_titles=[f'Sensor {sensor_id}' for sensor_id in top_sensors],\n",
    "#         vertical_spacing=0.1\n",
    "#     )\n",
    "\n",
    "#     # Add data for each sensor\n",
    "#     for i, sensor_id in enumerate(top_sensors):\n",
    "#         series = time_series_dict[sensor_id]\n",
    "\n",
    "#         # Add the raw time series\n",
    "#         fig.add_trace(\n",
    "#             go.Scatter(\n",
    "#                 x=series.index,\n",
    "#                 y=series.values,\n",
    "#                 mode='lines',\n",
    "#                 name=f'Sensor {sensor_id}',\n",
    "#                 line=dict(color='darkgray')\n",
    "#             ),\n",
    "#             row=i+1,\n",
    "#             col=1\n",
    "#         )\n",
    "\n",
    "#         # Find continuous segments\n",
    "#         segments = find_continuous_segments(series.index, series.values)\n",
    "\n",
    "#         # Add segment highlights for one example segment\n",
    "#         for j, (start_seg, end_seg) in enumerate(segments):\n",
    "#             if j > 2:  # Limit to first 3 segments to avoid overcrowding\n",
    "#                 break\n",
    "\n",
    "#             segment_indices = series.index[start_seg:end_seg]\n",
    "\n",
    "#             # Add segment highlight\n",
    "#             fig.add_trace(\n",
    "#                 go.Scatter(\n",
    "#                     x=[segment_indices[0], segment_indices[0], segment_indices[-1], segment_indices[-1], segment_indices[0]],\n",
    "#                     y=[series.min(), series.max(), series.max(), series.min(), series.min()],\n",
    "#                     fill=\"toself\",\n",
    "#                     mode='none',\n",
    "#                     name=f'S{sensor_id} Segment {j+1}',\n",
    "#                     fillcolor=f'rgba(144,238,144,0.2)',\n",
    "#                     showlegend=True\n",
    "#                 ),\n",
    "#                 row=i+1,\n",
    "#                 col=1\n",
    "#             )\n",
    "\n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         height=300*n_sensors,\n",
    "#         title_text=\"Time Windows Across Multiple Sensors\",\n",
    "#         showlegend=True,\n",
    "#         legend=dict(orientation=\"h\", y=-0.1)\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create a PCA visualization of sensor windows\n",
    "# def visualize_window_pca(time_series_dict, window_size=24, n_sensors=10):\n",
    "#     \"\"\"Create a PCA visualization of sensor windows to see patterns\"\"\"\n",
    "#     # Collect window data\n",
    "#     windows_data = []\n",
    "#     sensor_ids = []\n",
    "\n",
    "#     # Process top sensors\n",
    "#     sensor_data_counts = {sensor_id: len(series) for sensor_id, series in time_series_dict.items()}\n",
    "#     top_sensors = sorted(sensor_data_counts, key=sensor_data_counts.get, reverse=True)[:n_sensors]\n",
    "\n",
    "#     for sensor_id in top_sensors:\n",
    "#         series = time_series_dict[sensor_id]\n",
    "\n",
    "#         # Find continuous segments\n",
    "#         segments = find_continuous_segments(series.index, series.values)\n",
    "\n",
    "#         # Extract windows\n",
    "#         for start_seg, end_seg in segments:\n",
    "#             segment_values = series.values[start_seg:end_seg]\n",
    "\n",
    "#             # Create windows\n",
    "#             for i in range(0, len(segment_values) - window_size + 1, window_size//2):  # 50% overlap\n",
    "#                 window = segment_values[i:i+window_size]\n",
    "\n",
    "#                 if not np.isnan(window).any():  # Skip windows with NaN values\n",
    "#                     windows_data.append(window)\n",
    "#                     sensor_ids.append(sensor_id)\n",
    "\n",
    "#     if not windows_data:\n",
    "#         return None\n",
    "\n",
    "#     # Convert to numpy array\n",
    "#     X = np.array(windows_data)\n",
    "\n",
    "#     # Normalize the data\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#     # Apply PCA\n",
    "#     pca = PCA(n_components=2)\n",
    "#     X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "#     # Create a DataFrame for plotting\n",
    "#     pca_df = pd.DataFrame({\n",
    "#         'PC1': X_pca[:, 0],\n",
    "#         'PC2': X_pca[:, 1],\n",
    "#         'sensor_id': sensor_ids\n",
    "#     })\n",
    "\n",
    "#     # Create a scatter plot\n",
    "#     fig = px.scatter(\n",
    "#         pca_df,\n",
    "#         x='PC1',\n",
    "#         y='PC2',\n",
    "#         color='sensor_id',\n",
    "#         title='PCA of Sensor Windows',\n",
    "#         labels={'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)',\n",
    "#                 'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)'},\n",
    "#         hover_data=['sensor_id']\n",
    "#     )\n",
    "\n",
    "#     fig.update_layout(height=700, width=900)\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create a window count bar chart\n",
    "# def interactive_window_counts(time_series_dict, window_size=24, n_sensors=20):\n",
    "#     \"\"\"Create an interactive bar chart of window counts by sensor\"\"\"\n",
    "#     # Count windows per sensor\n",
    "#     window_counts = {}\n",
    "\n",
    "#     for sensor_id, series in time_series_dict.items():\n",
    "#         # Find segments without large gaps\n",
    "#         segments = find_continuous_segments(series.index, series.values)\n",
    "\n",
    "#         # Count windows\n",
    "#         total_windows = 0\n",
    "#         for start_seg, end_seg in segments:\n",
    "#             segment_len = end_seg - start_seg\n",
    "#             total_windows += max(0, segment_len - window_size + 1)\n",
    "\n",
    "#         window_counts[sensor_id] = total_windows\n",
    "\n",
    "#     # Sort by window count\n",
    "#     sorted_counts = sorted(window_counts.items(), key=lambda x: x[1], reverse=True)[:n_sensors]\n",
    "\n",
    "#     # Create a DataFrame\n",
    "#     count_df = pd.DataFrame(sorted_counts, columns=['sensor_id', 'window_count'])\n",
    "\n",
    "#     # Create a bar chart\n",
    "#     fig = px.bar(\n",
    "#         count_df,\n",
    "#         x='sensor_id',\n",
    "#         y='window_count',\n",
    "#         title=f'Number of Available Windows (size={window_size}) by Sensor',\n",
    "#         labels={'sensor_id': 'Sensor ID', 'window_count': 'Number of Windows'},\n",
    "#         color='window_count',\n",
    "#         color_continuous_scale=px.colors.sequential.Viridis\n",
    "#     )\n",
    "\n",
    "#     fig.update_layout(height=600, xaxis_tickangle=-45)\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create a heatmap of daily patterns\n",
    "# def visualize_daily_patterns(time_series_dict, n_sensors=6):\n",
    "#     \"\"\"Create a heatmap of daily patterns for top sensors\"\"\"\n",
    "#     # Identify sensors with most data points\n",
    "#     sensor_data_counts = {sensor_id: len(series) for sensor_id, series in time_series_dict.items()}\n",
    "#     top_sensors = sorted(sensor_data_counts, key=sensor_data_counts.get, reverse=True)[:n_sensors]\n",
    "\n",
    "#     # Create subplots\n",
    "#     fig = make_subplots(\n",
    "#         rows=n_sensors,\n",
    "#         cols=1,\n",
    "#         subplot_titles=[f'Sensor {sensor_id} - Daily Pattern' for sensor_id in top_sensors],\n",
    "#         vertical_spacing=0.08\n",
    "#     )\n",
    "\n",
    "#     # Process each sensor\n",
    "#     for i, sensor_id in enumerate(top_sensors):\n",
    "#         series = time_series_dict[sensor_id]\n",
    "\n",
    "#         # Create a DataFrame with hour and day of week\n",
    "#         df = pd.DataFrame({\n",
    "#             'value': series.values,\n",
    "#             'hour': series.index.hour,\n",
    "#             'day_of_week': series.index.dayofweek\n",
    "#         })\n",
    "\n",
    "#         # Group by hour and day of week\n",
    "#         pivot_data = df.pivot_table(\n",
    "#             values='value',\n",
    "#             index='day_of_week',\n",
    "#             columns='hour',\n",
    "#             aggfunc='mean'\n",
    "#         ).fillna(0)\n",
    "\n",
    "#         # Create heatmap\n",
    "#         heatmap = go.Heatmap(\n",
    "#             z=pivot_data.values,\n",
    "#             x=pivot_data.columns,\n",
    "#             y=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n",
    "#             colorscale='Viridis',\n",
    "#             showscale=(i==0),  # Only show colorbar for first heatmap\n",
    "#         )\n",
    "\n",
    "#         fig.add_trace(heatmap, row=i+1, col=1)\n",
    "\n",
    "#         # Update axes\n",
    "#         fig.update_xaxes(title_text=\"Hour of Day\" if i==n_sensors-1 else \"\", row=i+1, col=1)\n",
    "#         fig.update_yaxes(title_text=\"Day of Week\", row=i+1, col=1)\n",
    "\n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         height=250*n_sensors,\n",
    "#         title_text=\"Daily Traffic Patterns Across Sensors\"\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Function to create all interactive visualizations\n",
    "# def create_interactive_visualizations(data_file='test_data_1yr.pkl', window_size=24):\n",
    "#     \"\"\"Create and return a list of interactive visualizations for time window analysis\"\"\"\n",
    "#     # Load the data\n",
    "#     time_series_dict = load_data(data_file)\n",
    "\n",
    "#     # Create visualizations\n",
    "#     visualizations = []\n",
    "\n",
    "#     # 1. Data availability heatmap\n",
    "#     viz1 = interactive_data_availability(time_series_dict)\n",
    "#     visualizations.append(('data_availability', viz1))\n",
    "\n",
    "#     # 2. Window dashboard for top sensors\n",
    "#     viz2 = interactive_window_dashboard(time_series_dict, window_size=window_size)\n",
    "#     visualizations.append(('window_dashboard', viz2))\n",
    "\n",
    "#     # 3. Window counts\n",
    "#     viz3 = interactive_window_counts(time_series_dict, window_size=window_size)\n",
    "#     visualizations.append(('window_counts', viz3))\n",
    "\n",
    "#     # 4. PCA of windows\n",
    "#     viz4 = visualize_window_pca(time_series_dict, window_size=window_size)\n",
    "#     visualizations.append(('window_pca', viz4))\n",
    "\n",
    "#     # 5. Daily patterns heatmap\n",
    "#     viz5 = visualize_daily_patterns(time_series_dict)\n",
    "#     visualizations.append(('daily_patterns', viz5))\n",
    "\n",
    "#     return visualizations\n",
    "\n",
    "# # Create a comprehensive dashboard combining multiple visualizations\n",
    "# def create_sensor_window_dashboard(data_file='test_data_1yr.pkl', window_size=24):\n",
    "#     \"\"\"Create a comprehensive dashboard for analyzing sensor time windows\"\"\"\n",
    "#     # Load the data\n",
    "#     time_series_dict = load_data(data_file)\n",
    "\n",
    "#     # Identify sensors with most data points for individual analysis\n",
    "#     sensor_data_counts = {sensor_id: len(series) for sensor_id, series in time_series_dict.items()}\n",
    "#     top_sensor = max(sensor_data_counts, key=sensor_data_counts.get)\n",
    "\n",
    "#     # Create a multi-page dashboard using HTML and Plotly\n",
    "#     from plotly.io import to_html\n",
    "#     import plotly.io as pio\n",
    "\n",
    "#     # Set theme\n",
    "#     pio.templates.default = \"plotly_white\"\n",
    "\n",
    "#     # Create individual visualizations\n",
    "#     data_avail_fig = interactive_data_availability(time_series_dict)\n",
    "#     top_sensor_fig = interactive_sensor_windows(time_series_dict, top_sensor, window_size)\n",
    "#     window_counts_fig = interactive_window_counts(time_series_dict, window_size)\n",
    "#     daily_patterns_fig = visualize_daily_patterns(time_series_dict, n_sensors=4)\n",
    "\n",
    "#     # Try to create PCA visualization if possible\n",
    "#     try:\n",
    "#         pca_fig = visualize_window_pca(time_series_dict, window_size)\n",
    "#     except:\n",
    "#         pca_fig = None\n",
    "\n",
    "#     # Combine into HTML\n",
    "#     html_content = f\"\"\"\n",
    "#     <!DOCTYPE html>\n",
    "#     <html>\n",
    "#     <head>\n",
    "#         <title>Sensor Window Analysis Dashboard</title>\n",
    "#         <style>\n",
    "#             body {{\n",
    "#                 font-family: Arial, sans-serif;\n",
    "#                 margin: 0;\n",
    "#                 padding: 20px;\n",
    "#                 background-color: #f5f5f5;\n",
    "#             }}\n",
    "#             .dashboard-container {{\n",
    "#                 max-width: 1200px;\n",
    "#                 margin: 0 auto;\n",
    "#                 background-color: white;\n",
    "#                 border-radius: 8px;\n",
    "#                 overflow: hidden;\n",
    "#                 box-shadow: 0 0 10px rgba(0,0,0,0.1);\n",
    "#             }}\n",
    "#             .dashboard-header {{\n",
    "#                 background-color: #4C78A8;\n",
    "#                 color: white;\n",
    "#                 padding: 20px;\n",
    "#                 text-align: center;\n",
    "#             }}\n",
    "#             .dashboard-section {{\n",
    "#                 padding: 20px;\n",
    "#                 margin-bottom: 20px;\n",
    "#                 border-bottom: 1px solid #eee;\n",
    "#             }}\n",
    "#             h1 {{\n",
    "#                 margin: 0;\n",
    "#             }}\n",
    "#             h2 {{\n",
    "#                 color: #2C3E50;\n",
    "#                 margin-top: 0;\n",
    "#             }}\n",
    "#             .viz-container {{\n",
    "#                 margin-top: 20px;\n",
    "#             }}\n",
    "#         </style>\n",
    "#     </head>\n",
    "#     <body>\n",
    "#         <div class=\"dashboard-container\">\n",
    "#             <div class=\"dashboard-header\">\n",
    "#                 <h1>Sensor Time Window Analysis Dashboard</h1>\n",
    "#                 <p>Window Size: {window_size} time steps</p>\n",
    "#             </div>\n",
    "\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>Data Availability Overview</h2>\n",
    "#                 <p>This heatmap shows when data is available across all sensors. Darker blue indicates data availability.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(data_avail_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>Time Windows for Top Sensor (ID: {top_sensor})</h2>\n",
    "#                 <p>This visualization shows the raw data for the sensor with the most data points, highlighting continuous segments and example windows.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(top_sensor_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>Window Count Distribution</h2>\n",
    "#                 <p>This bar chart shows the number of available windows for each sensor.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(window_counts_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>Daily Traffic Patterns</h2>\n",
    "#                 <p>These heatmaps show the average traffic patterns by hour of day and day of week for top sensors.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(daily_patterns_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Add PCA visualization if available\n",
    "#     if pca_fig is not None:\n",
    "#         html_content += f\"\"\"\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>PCA of Sensor Windows</h2>\n",
    "#                 <p>This scatter plot shows a 2D representation of the window patterns across sensors using Principal Component Analysis.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(pca_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "#         \"\"\"\n",
    "\n",
    "#     # Close HTML\n",
    "#     html_content += \"\"\"\n",
    "#         </div>\n",
    "#     </body>\n",
    "#     </html>\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Return the HTML content\n",
    "#     return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_dict = load_data(\"data/test_data_1yr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_dict[\"10000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn_package.config import ExperimentConfig\n",
    "\n",
    "\n",
    "def compute_completeness(time_series_dict):\n",
    "    config = ExperimentConfig(\n",
    "        \"/Users/administrator/Code/python/phd-project-gnn/config.yml\"\n",
    "    )\n",
    "    start_date = datetime.strptime(config.data.start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date = datetime.strptime(config.data.end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    days_between = (end_date - start_date).total_seconds() / (60 * 60 * 24)\n",
    "    expected_records = days_between * 24 * 4\n",
    "    print(f\"Total days between start and end date: {days_between}\")\n",
    "    completeness_dict = {}\n",
    "    for keys, series in time_series_dict.items():\n",
    "        series = series[~series.index.duplicated(keep=\"first\")]\n",
    "        completeness_dict[keys] = len(series) / expected_records\n",
    "    return completeness_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.strptime(config.data.start_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "end_date = datetime.strptime(config.data.end_date, \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_series_dict[\"10000\"])\n",
    "type(time_series_dict[\"10000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_dict = compute_completeness(time_series_dict)\n",
    "for keys, values in completeness_dict.items():\n",
    "    print(keys)\n",
    "    print(values)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dashboards.utils import load_sensor_geojson\n",
    "\n",
    "\n",
    "def completeness_map(time_series_dict):\n",
    "    # Load the sensor geojson\n",
    "    sensor_geojson = load_sensor_geojson(\n",
    "        \"/Users/administrator/Code/python/phd-project-gnn/dashboards/data/sensors.geojson\"\n",
    "    )\n",
    "\n",
    "    # Create the map\n",
    "    fig = px.choropleth_mapbox(\n",
    "        sensor_geojson,\n",
    "        geojson=sensor_geojson,\n",
    "        locations=\"id\",\n",
    "        featureidkey=\"properties.id\",\n",
    "        color=\"completeness\",\n",
    "        color_continuous_scale=\"Viridis\",\n",
    "        range_color=(0, 1),\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        zoom=10,\n",
    "        center={\"lat\": 37.7749, \"lon\": -122.4194},\n",
    "        opacity=0.5,\n",
    "        labels={\"completeness\": \"Completeness\"},\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_map(time_series_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Or create a complete dashboard\n",
    "# dashboard_html = create_sensor_window_dashboard(data_file='../test_data_1yr.pkl', window_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the HTML to a file\n",
    "# with open('sensor_dashboard.html', 'w') as f:\n",
    "#     f.write(dashboard_html)\n",
    "\n",
    "# print(\"Dashboard saved to sensor_dashboard.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
