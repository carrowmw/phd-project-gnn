{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Helper function to load data from file if it exists\n",
    "def load_data(file_path=\"../test_data_1yr.pkl\"):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "# Function to create heatmap of data availability\n",
    "def visualize_data_availability(time_series_dict, figsize=(20, 10)):\n",
    "    \"\"\"Create a heatmap showing data availability across sensors over time\"\"\"\n",
    "    # Get all unique timestamps from all sensors\n",
    "    all_timestamps = set()\n",
    "    for sensor_id, series in time_series_dict.items():\n",
    "        all_timestamps.update(series.index)\n",
    "\n",
    "    all_timestamps = sorted(all_timestamps)\n",
    "\n",
    "    # Create a DataFrame with all timestamps and fill with NaN\n",
    "    data_matrix = pd.DataFrame(index=all_timestamps)\n",
    "\n",
    "    # For each sensor, add a column to the DataFrame\n",
    "    for sensor_id, series in time_series_dict.items():\n",
    "        data_matrix[sensor_id] = np.nan\n",
    "        # Only fill in data that exists\n",
    "        data_matrix.loc[series.index, sensor_id] = 1\n",
    "\n",
    "    # Resample to a lower resolution for better visualization if too many datapoints\n",
    "    if len(all_timestamps) > 1000:\n",
    "        data_matrix = data_matrix.resample(\"1H\").mean()\n",
    "\n",
    "    # Create a custom colormap (white for NaN, blue gradient for data)\n",
    "    colors = [\"white\", \"#deebf7\", \"#9ecae1\", \"#3182bd\"]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=256)\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.heatmap(data_matrix.T, cmap=cmap, cbar=False)\n",
    "\n",
    "    # Format the x-axis to show time\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.title(\"Data Availability Across Sensors\", fontsize=16)\n",
    "    plt.ylabel(\"Sensor ID\", fontsize=12)\n",
    "    plt.xlabel(\"Date\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "# Function to visualize time windows for a subset of sensors\n",
    "def visualize_time_windows(\n",
    "    time_series_dict, window_size=24, stride=1, n_sensors=6, figsize=(20, 15)\n",
    "):\n",
    "    \"\"\"Visualize time windows for selected sensors\"\"\"\n",
    "    # Identify sensors with most data points\n",
    "    sensor_data_counts = {\n",
    "        sensor_id: len(series) for sensor_id, series in time_series_dict.items()\n",
    "    }\n",
    "    top_sensors = sorted(sensor_data_counts, key=sensor_data_counts.get, reverse=True)[\n",
    "        :n_sensors\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(n_sensors, 1, figsize=figsize)\n",
    "\n",
    "    for i, sensor_id in enumerate(top_sensors):\n",
    "        series = time_series_dict[sensor_id]\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Plot the raw time series\n",
    "        ax.plot(series.index, series.values, color=\"gray\", alpha=0.7, label=\"Raw data\")\n",
    "\n",
    "        # Find segments without large gaps\n",
    "        # Simulating the TimeSeriesPreprocessor logic\n",
    "        segments = []\n",
    "        start_idx = 0\n",
    "        gap_threshold = pd.Timedelta(minutes=15)\n",
    "\n",
    "        for j in range(1, len(series.index)):\n",
    "            time_diff = series.index[j] - series.index[j - 1]\n",
    "\n",
    "            if time_diff > gap_threshold or (\n",
    "                np.isnan(series.values[j - 1]) or np.isnan(series.values[j])\n",
    "            ):\n",
    "                if j - start_idx >= window_size:\n",
    "                    segments.append((start_idx, j))\n",
    "                start_idx = j\n",
    "\n",
    "        # Add the last segment if it's long enough\n",
    "        if len(series.index) - start_idx >= window_size:\n",
    "            segments.append((start_idx, len(series.index)))\n",
    "\n",
    "        # Highlight windows for each segment\n",
    "        for start_seg, end_seg in segments:\n",
    "            segment_values = series.values[start_seg:end_seg]\n",
    "            segment_indices = series.index[start_seg:end_seg]\n",
    "\n",
    "            # Draw segment boundaries\n",
    "            ax.axvspan(\n",
    "                segment_indices[0], segment_indices[-1], color=\"lightgreen\", alpha=0.2\n",
    "            )\n",
    "\n",
    "            # Draw window samples\n",
    "            for j in range(0, len(segment_values) - window_size + 1, stride):\n",
    "                window_start = segment_indices[j]\n",
    "                window_end = segment_indices[j + window_size - 1]\n",
    "\n",
    "                # Only show a subset of windows to avoid overcrowding\n",
    "                if j % 20 == 0:  # Show every 20th window\n",
    "                    ax.axvspan(window_start, window_end, color=\"blue\", alpha=0.1)\n",
    "\n",
    "        ax.set_title(f\"Sensor ID: {sensor_id}\", fontsize=12)\n",
    "        ax.set_ylabel(\"Traffic Count\", fontsize=10)\n",
    "\n",
    "        # Format x-axis\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "        ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))\n",
    "\n",
    "    axes[-1].set_xlabel(\"Date\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Function to create a comparison of window distributions\n",
    "def visualize_window_distributions(\n",
    "    time_series_dict, window_size=24, n_sensors=15, figsize=(16, 10)\n",
    "):\n",
    "    \"\"\"Create a visualization showing the distribution of windows across sensors\"\"\"\n",
    "    # Count windows per sensor\n",
    "    window_counts = {}\n",
    "\n",
    "    gap_threshold = pd.Timedelta(minutes=15)\n",
    "\n",
    "    for sensor_id, series in time_series_dict.items():\n",
    "        # Find segments without large gaps (like TimeSeriesPreprocessor)\n",
    "        segments = []\n",
    "        start_idx = 0\n",
    "\n",
    "        for j in range(1, len(series.index)):\n",
    "            time_diff = series.index[j] - series.index[j - 1]\n",
    "\n",
    "            if time_diff > gap_threshold or (\n",
    "                np.isnan(series.values[j - 1]) or np.isnan(series.values[j])\n",
    "            ):\n",
    "                if j - start_idx >= window_size:\n",
    "                    segments.append((start_idx, j))\n",
    "                start_idx = j\n",
    "\n",
    "        # Add the last segment if it's long enough\n",
    "        if len(series.index) - start_idx >= window_size:\n",
    "            segments.append((start_idx, len(series.index)))\n",
    "\n",
    "        # Count windows\n",
    "        total_windows = 0\n",
    "        for start_seg, end_seg in segments:\n",
    "            segment_len = end_seg - start_seg\n",
    "            total_windows += max(0, segment_len - window_size + 1)\n",
    "\n",
    "        window_counts[sensor_id] = total_windows\n",
    "\n",
    "    # Sort by window count\n",
    "    top_sensors = sorted(window_counts.items(), key=lambda x: x[1], reverse=True)[\n",
    "        :n_sensors\n",
    "    ]\n",
    "\n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.barplot(\n",
    "        x=[s[0] for s in top_sensors], y=[s[1] for s in top_sensors], palette=\"viridis\"\n",
    "    )\n",
    "\n",
    "    plt.title(\n",
    "        f\"Number of Available Windows (size={window_size}) by Sensor\", fontsize=16\n",
    "    )\n",
    "    plt.ylabel(\"Number of Windows\", fontsize=12)\n",
    "    plt.xlabel(\"Sensor ID\", fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "# Function to create a histogram of window values\n",
    "def visualize_window_value_distributions(\n",
    "    time_series_dict, window_size=24, n_sensors=5, figsize=(18, 12)\n",
    "):\n",
    "    \"\"\"Create histograms of window values for top sensors\"\"\"\n",
    "    # Count data points per sensor to identify top sensors\n",
    "    sensor_data_counts = {\n",
    "        sensor_id: len(series) for sensor_id, series in time_series_dict.items()\n",
    "    }\n",
    "    top_sensors = sorted(sensor_data_counts, key=sensor_data_counts.get, reverse=True)[\n",
    "        :n_sensors\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(n_sensors, 2, figsize=figsize)\n",
    "\n",
    "    for i, sensor_id in enumerate(top_sensors):\n",
    "        series = time_series_dict[sensor_id]\n",
    "\n",
    "        # Histogram of all values\n",
    "        sns.histplot(series.values, kde=True, ax=axes[i, 0])\n",
    "        axes[i, 0].set_title(f\"Sensor {sensor_id} - All Values\", fontsize=12)\n",
    "        axes[i, 0].set_xlabel(\"Traffic Count\", fontsize=10)\n",
    "\n",
    "        # Time series with daily pattern visualization\n",
    "        if len(series) > 24 * 4:  # At least 1 day of data (assuming 15-min intervals)\n",
    "            # Convert to hour of day\n",
    "            hour_of_day = series.index.hour + series.index.minute / 60\n",
    "\n",
    "            # Create a scatter plot of hour vs value\n",
    "            sns.scatterplot(x=hour_of_day, y=series.values, alpha=0.5, ax=axes[i, 1])\n",
    "\n",
    "            # Add a smoothed trend line\n",
    "            try:\n",
    "                sns.regplot(\n",
    "                    x=hour_of_day,\n",
    "                    y=series.values,\n",
    "                    scatter=False,\n",
    "                    order=4,\n",
    "                    ax=axes[i, 1],\n",
    "                    color=\"red\",\n",
    "                )\n",
    "            except:\n",
    "                # If there's an error with the regression, skip it\n",
    "                pass\n",
    "\n",
    "            axes[i, 1].set_title(f\"Sensor {sensor_id} - Daily Pattern\", fontsize=12)\n",
    "            axes[i, 1].set_xlabel(\"Hour of Day\", fontsize=10)\n",
    "            axes[i, 1].set_ylabel(\"Traffic Count\", fontsize=10)\n",
    "            axes[i, 1].set_xlim(0, 24)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Function to visualize a calendar heatmap for a single sensor\n",
    "def visualize_calendar_heatmap(time_series_dict, sensor_id=None, figsize=(20, 6)):\n",
    "    \"\"\"Create a calendar heatmap for a specific sensor\"\"\"\n",
    "    # Choose the sensor with the most data points if not specified\n",
    "    if sensor_id is None:\n",
    "        sensor_data_counts = {\n",
    "            sensor_id: len(series) for sensor_id, series in time_series_dict.items()\n",
    "        }\n",
    "        sensor_id = max(sensor_data_counts, key=sensor_data_counts.get)\n",
    "\n",
    "    series = time_series_dict.get(sensor_id)\n",
    "    if series is None or len(series) == 0:\n",
    "        return None\n",
    "\n",
    "    # Resample to hourly data\n",
    "    hourly_data = series.resample(\"1H\").mean()\n",
    "\n",
    "    # Create a DataFrame with date as index and hour as columns\n",
    "    pivot_data = hourly_data.reset_index()\n",
    "    pivot_data[\"date\"] = pivot_data[\"index\"].dt.date\n",
    "    pivot_data[\"hour\"] = pivot_data[\"index\"].dt.hour\n",
    "\n",
    "    # Pivot the table\n",
    "    calendar_data = pivot_data.pivot(index=\"date\", columns=\"hour\", values=0)\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.heatmap(calendar_data, cmap=\"viridis\", robust=True)\n",
    "\n",
    "    plt.title(f\"Calendar Heatmap for Sensor {sensor_id}\", fontsize=16)\n",
    "    plt.xlabel(\"Hour of Day\", fontsize=12)\n",
    "    plt.ylabel(\"Date\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "# Main function to create all visualizations\n",
    "def create_time_window_visualizations(data_file=\"../test_data_1yr.pkl\", window_size=24):\n",
    "    \"\"\"Create and return a list of visualizations for time window analysis\"\"\"\n",
    "    # Load the data\n",
    "    time_series_dict = load_data(data_file)\n",
    "\n",
    "    # Create visualizations\n",
    "    visualizations = []\n",
    "\n",
    "    # 1. Data availability heatmap\n",
    "    viz1 = visualize_data_availability(time_series_dict)\n",
    "    visualizations.append((\"data_availability\", viz1))\n",
    "\n",
    "    # 2. Time windows visualization for top sensors\n",
    "    viz2 = visualize_time_windows(time_series_dict, window_size=window_size)\n",
    "    visualizations.append((\"time_windows\", viz2))\n",
    "\n",
    "    # 3. Window count distribution\n",
    "    viz3 = visualize_window_distributions(time_series_dict, window_size=window_size)\n",
    "    visualizations.append((\"window_distribution\", viz3))\n",
    "\n",
    "    # 4. Window value distributions\n",
    "    viz4 = visualize_window_value_distributions(\n",
    "        time_series_dict, window_size=window_size\n",
    "    )\n",
    "    visualizations.append((\"value_distribution\", viz4))\n",
    "\n",
    "    # 5. Calendar heatmap for the sensor with most data\n",
    "    viz5 = visualize_calendar_heatmap(time_series_dict)\n",
    "    visualizations.append((\"calendar_heatmap\", viz5))\n",
    "\n",
    "    return visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations = create_time_window_visualizations()\n",
    "\n",
    "for name, fig in visualizations:\n",
    "    plt.figure(fig.number)\n",
    "    plt.savefig(f\"{name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Helper function to load data from file\n",
    "# def load_data(file_path='test_data_1yr.pkl'):\n",
    "#     with open(file_path, 'rb') as f:\n",
    "#         return pickle.load(f)\n",
    "\n",
    "# # Find continuous segments in time series\n",
    "# def find_continuous_segments(time_index, values, gap_threshold=pd.Timedelta(minutes=15)):\n",
    "#     segments = []\n",
    "#     start_idx = 0\n",
    "\n",
    "#     for i in range(1, len(time_index)):\n",
    "#         time_diff = time_index[i] - time_index[i-1]\n",
    "\n",
    "#         # Check for gaps in time or values\n",
    "#         if (time_diff > gap_threshold) or (np.isnan(values[i-1]) or np.isnan(values[i])):\n",
    "#             if i - start_idx >= 24:  # Assuming minimum window size of 24\n",
    "#                 segments.append((start_idx, i))\n",
    "#             start_idx = i\n",
    "\n",
    "#     # Add the last segment if it's long enough\n",
    "#     if len(time_index) - start_idx >= 24:\n",
    "#         segments.append((start_idx, len(time_index)))\n",
    "\n",
    "#     return segments\n",
    "\n",
    "# # Create an interactive data availability heatmap\n",
    "# def interactive_data_availability(time_series_dict):\n",
    "#     \"\"\"Create an interactive heatmap showing data availability across sensors over time\"\"\"\n",
    "#     # Get all unique timestamps from all sensors\n",
    "#     all_timestamps = set()\n",
    "#     for sensor_id, series in time_series_dict.items():\n",
    "#         all_timestamps.update(series.index)\n",
    "\n",
    "#     all_timestamps = sorted(all_timestamps)\n",
    "\n",
    "#     # Create a DataFrame with all timestamps and fill with NaN\n",
    "#     data_matrix = pd.DataFrame(index=all_timestamps)\n",
    "\n",
    "#     # For each sensor, add a column to the DataFrame\n",
    "#     for sensor_id, series in time_series_dict.items():\n",
    "#         data_matrix[sensor_id] = np.nan\n",
    "#         # Only fill in data that exists\n",
    "#         data_matrix.loc[series.index, sensor_id] = 1\n",
    "\n",
    "#     # Resample to a lower resolution for better visualization if too many datapoints\n",
    "#     if len(all_timestamps) > 1000:\n",
    "#         data_matrix = data_matrix.resample('1H').mean()\n",
    "\n",
    "#     # Convert to long format for plotly\n",
    "#     data_long = data_matrix.reset_index().melt(\n",
    "#         id_vars='index',\n",
    "#         var_name='sensor_id',\n",
    "#         value_name='has_data'\n",
    "#     )\n",
    "\n",
    "#     # Create the heatmap with plotly\n",
    "#     fig = px.density_heatmap(\n",
    "#         data_long,\n",
    "#         x='index',\n",
    "#         y='sensor_id',\n",
    "#         z='has_data',\n",
    "#         color_continuous_scale=[\n",
    "#             [0, 'rgba(255,255,255,0)'],  # Transparent for NaN\n",
    "#             [0.5, 'rgba(222,235,247,1)'],  # Light blue\n",
    "#             [1, 'rgba(49,130,189,1)']      # Dark blue\n",
    "#         ],\n",
    "#         title='Data Availability Across Sensors (Interactive)',\n",
    "#         labels={'index': 'Date', 'sensor_id': 'Sensor ID', 'has_data': 'Data Available'}\n",
    "#     )\n",
    "\n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         height=800,\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Sensor ID',\n",
    "#         title_x=0.5,\n",
    "#         coloraxis_showscale=False\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create interactive window visualization for a given sensor\n",
    "# def interactive_sensor_windows(time_series_dict, sensor_id, window_size=24, stride=1):\n",
    "#     \"\"\"Create an interactive visualization of windows for a specific sensor\"\"\"\n",
    "#     series = time_series_dict.get(sensor_id)\n",
    "#     if series is None or len(series) == 0:\n",
    "#         return None\n",
    "\n",
    "#     # Find continuous segments\n",
    "#     segments = find_continuous_segments(series.index, series.values)\n",
    "\n",
    "#     # Create a figure\n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     # Add the raw time series\n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         x=series.index,\n",
    "#         y=series.values,\n",
    "#         mode='lines',\n",
    "#         name='Raw Data',\n",
    "#         line=dict(color='darkgray')\n",
    "#     ))\n",
    "\n",
    "#     # Add segments and windows\n",
    "#     for start_seg, end_seg in segments:\n",
    "#         segment_indices = series.index[start_seg:end_seg]\n",
    "\n",
    "#         # Add segment highlight\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             x=[segment_indices[0], segment_indices[0], segment_indices[-1], segment_indices[-1]],\n",
    "#             y=[series.values.min(), series.values.max(), series.values.max(), series.values.min()],\n",
    "#             fill=\"toself\",\n",
    "#             mode='none',\n",
    "#             name=f'Segment: {segment_indices[0].date()} to {segment_indices[-1].date()}',\n",
    "#             fillcolor='rgba(144,238,144,0.2)',\n",
    "#             showlegend=True\n",
    "#         ))\n",
    "\n",
    "#         # Add a few example windows\n",
    "#         n_windows = len(segment_indices) - window_size + 1\n",
    "\n",
    "#         # Only show a few windows to avoid overcrowding\n",
    "#         window_step = max(1, n_windows // 5)\n",
    "\n",
    "#         for i in range(0, n_windows, window_step):\n",
    "#             window_start = segment_indices[i]\n",
    "#             window_end = segment_indices[i + window_size - 1]\n",
    "\n",
    "#             fig.add_trace(go.Scatter(\n",
    "#                 x=[window_start, window_start, window_end, window_end],\n",
    "#                 y=[series.values.min(), series.values.max(), series.values.max(), series.values.min()],\n",
    "#                 fill=\"toself\",\n",
    "#                 mode='none',\n",
    "#                 name=f'Window: {window_start}',\n",
    "#                 fillcolor='rgba(0,0,255,0.1)',\n",
    "#                 showlegend=False\n",
    "#             ))\n",
    "\n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         title=f'Time Windows for Sensor {sensor_id}',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Traffic Count',\n",
    "#         height=600,\n",
    "#         legend=dict(\n",
    "#             orientation=\"h\",\n",
    "#             yanchor=\"bottom\",\n",
    "#             y=1.02,\n",
    "#             xanchor=\"right\",\n",
    "#             x=1\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create a dashboard with multiple sensor window visualizations\n",
    "# def interactive_window_dashboard(time_series_dict, window_size=24, n_sensors=4):\n",
    "#     \"\"\"Create a dashboard with window visualizations for multiple sensors\"\"\"\n",
    "#     # Identify sensors with most data points\n",
    "#     sensor_data_counts = {sensor_id: len(series) for sensor_id, series in time_series_dict.items()}\n",
    "#     top_sensors = sorted(sensor_data_counts, key=sensor_data_counts.get, reverse=True)[:n_sensors]\n",
    "\n",
    "#     # Create subplots\n",
    "#     fig = make_subplots(\n",
    "#         rows=n_sensors,\n",
    "#         cols=1,\n",
    "#         subplot_titles=[f'Sensor {sensor_id}' for sensor_id in top_sensors],\n",
    "#         vertical_spacing=0.1\n",
    "#     )\n",
    "\n",
    "#     # Add data for each sensor\n",
    "#     for i, sensor_id in enumerate(top_sensors):\n",
    "#         series = time_series_dict[sensor_id]\n",
    "\n",
    "#         # Add the raw time series\n",
    "#         fig.add_trace(\n",
    "#             go.Scatter(\n",
    "#                 x=series.index,\n",
    "#                 y=series.values,\n",
    "#                 mode='lines',\n",
    "#                 name=f'Sensor {sensor_id}',\n",
    "#                 line=dict(color='darkgray')\n",
    "#             ),\n",
    "#             row=i+1,\n",
    "#             col=1\n",
    "#         )\n",
    "\n",
    "#         # Find continuous segments\n",
    "#         segments = find_continuous_segments(series.index, series.values)\n",
    "\n",
    "#         # Add segment highlights for one example segment\n",
    "#         for j, (start_seg, end_seg) in enumerate(segments):\n",
    "#             if j > 2:  # Limit to first 3 segments to avoid overcrowding\n",
    "#                 break\n",
    "\n",
    "#             segment_indices = series.index[start_seg:end_seg]\n",
    "\n",
    "#             # Add segment highlight\n",
    "#             fig.add_trace(\n",
    "#                 go.Scatter(\n",
    "#                     x=[segment_indices[0], segment_indices[0], segment_indices[-1], segment_indices[-1], segment_indices[0]],\n",
    "#                     y=[series.min(), series.max(), series.max(), series.min(), series.min()],\n",
    "#                     fill=\"toself\",\n",
    "#                     mode='none',\n",
    "#                     name=f'S{sensor_id} Segment {j+1}',\n",
    "#                     fillcolor=f'rgba(144,238,144,0.2)',\n",
    "#                     showlegend=True\n",
    "#                 ),\n",
    "#                 row=i+1,\n",
    "#                 col=1\n",
    "#             )\n",
    "\n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         height=300*n_sensors,\n",
    "#         title_text=\"Time Windows Across Multiple Sensors\",\n",
    "#         showlegend=True,\n",
    "#         legend=dict(orientation=\"h\", y=-0.1)\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create a PCA visualization of sensor windows\n",
    "# def visualize_window_pca(time_series_dict, window_size=24, n_sensors=10):\n",
    "#     \"\"\"Create a PCA visualization of sensor windows to see patterns\"\"\"\n",
    "#     # Collect window data\n",
    "#     windows_data = []\n",
    "#     sensor_ids = []\n",
    "\n",
    "#     # Process top sensors\n",
    "#     sensor_data_counts = {sensor_id: len(series) for sensor_id, series in time_series_dict.items()}\n",
    "#     top_sensors = sorted(sensor_data_counts, key=sensor_data_counts.get, reverse=True)[:n_sensors]\n",
    "\n",
    "#     for sensor_id in top_sensors:\n",
    "#         series = time_series_dict[sensor_id]\n",
    "\n",
    "#         # Find continuous segments\n",
    "#         segments = find_continuous_segments(series.index, series.values)\n",
    "\n",
    "#         # Extract windows\n",
    "#         for start_seg, end_seg in segments:\n",
    "#             segment_values = series.values[start_seg:end_seg]\n",
    "\n",
    "#             # Create windows\n",
    "#             for i in range(0, len(segment_values) - window_size + 1, window_size//2):  # 50% overlap\n",
    "#                 window = segment_values[i:i+window_size]\n",
    "\n",
    "#                 if not np.isnan(window).any():  # Skip windows with NaN values\n",
    "#                     windows_data.append(window)\n",
    "#                     sensor_ids.append(sensor_id)\n",
    "\n",
    "#     if not windows_data:\n",
    "#         return None\n",
    "\n",
    "#     # Convert to numpy array\n",
    "#     X = np.array(windows_data)\n",
    "\n",
    "#     # Normalize the data\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#     # Apply PCA\n",
    "#     pca = PCA(n_components=2)\n",
    "#     X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "#     # Create a DataFrame for plotting\n",
    "#     pca_df = pd.DataFrame({\n",
    "#         'PC1': X_pca[:, 0],\n",
    "#         'PC2': X_pca[:, 1],\n",
    "#         'sensor_id': sensor_ids\n",
    "#     })\n",
    "\n",
    "#     # Create a scatter plot\n",
    "#     fig = px.scatter(\n",
    "#         pca_df,\n",
    "#         x='PC1',\n",
    "#         y='PC2',\n",
    "#         color='sensor_id',\n",
    "#         title='PCA of Sensor Windows',\n",
    "#         labels={'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)',\n",
    "#                 'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)'},\n",
    "#         hover_data=['sensor_id']\n",
    "#     )\n",
    "\n",
    "#     fig.update_layout(height=700, width=900)\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create a window count bar chart\n",
    "# def interactive_window_counts(time_series_dict, window_size=24, n_sensors=20):\n",
    "#     \"\"\"Create an interactive bar chart of window counts by sensor\"\"\"\n",
    "#     # Count windows per sensor\n",
    "#     window_counts = {}\n",
    "\n",
    "#     for sensor_id, series in time_series_dict.items():\n",
    "#         # Find segments without large gaps\n",
    "#         segments = find_continuous_segments(series.index, series.values)\n",
    "\n",
    "#         # Count windows\n",
    "#         total_windows = 0\n",
    "#         for start_seg, end_seg in segments:\n",
    "#             segment_len = end_seg - start_seg\n",
    "#             total_windows += max(0, segment_len - window_size + 1)\n",
    "\n",
    "#         window_counts[sensor_id] = total_windows\n",
    "\n",
    "#     # Sort by window count\n",
    "#     sorted_counts = sorted(window_counts.items(), key=lambda x: x[1], reverse=True)[:n_sensors]\n",
    "\n",
    "#     # Create a DataFrame\n",
    "#     count_df = pd.DataFrame(sorted_counts, columns=['sensor_id', 'window_count'])\n",
    "\n",
    "#     # Create a bar chart\n",
    "#     fig = px.bar(\n",
    "#         count_df,\n",
    "#         x='sensor_id',\n",
    "#         y='window_count',\n",
    "#         title=f'Number of Available Windows (size={window_size}) by Sensor',\n",
    "#         labels={'sensor_id': 'Sensor ID', 'window_count': 'Number of Windows'},\n",
    "#         color='window_count',\n",
    "#         color_continuous_scale=px.colors.sequential.Viridis\n",
    "#     )\n",
    "\n",
    "#     fig.update_layout(height=600, xaxis_tickangle=-45)\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Create a heatmap of daily patterns\n",
    "# def visualize_daily_patterns(time_series_dict, n_sensors=6):\n",
    "#     \"\"\"Create a heatmap of daily patterns for top sensors\"\"\"\n",
    "#     # Identify sensors with most data points\n",
    "#     sensor_data_counts = {sensor_id: len(series) for sensor_id, series in time_series_dict.items()}\n",
    "#     top_sensors = sorted(sensor_data_counts, key=sensor_data_counts.get, reverse=True)[:n_sensors]\n",
    "\n",
    "#     # Create subplots\n",
    "#     fig = make_subplots(\n",
    "#         rows=n_sensors,\n",
    "#         cols=1,\n",
    "#         subplot_titles=[f'Sensor {sensor_id} - Daily Pattern' for sensor_id in top_sensors],\n",
    "#         vertical_spacing=0.08\n",
    "#     )\n",
    "\n",
    "#     # Process each sensor\n",
    "#     for i, sensor_id in enumerate(top_sensors):\n",
    "#         series = time_series_dict[sensor_id]\n",
    "\n",
    "#         # Create a DataFrame with hour and day of week\n",
    "#         df = pd.DataFrame({\n",
    "#             'value': series.values,\n",
    "#             'hour': series.index.hour,\n",
    "#             'day_of_week': series.index.dayofweek\n",
    "#         })\n",
    "\n",
    "#         # Group by hour and day of week\n",
    "#         pivot_data = df.pivot_table(\n",
    "#             values='value',\n",
    "#             index='day_of_week',\n",
    "#             columns='hour',\n",
    "#             aggfunc='mean'\n",
    "#         ).fillna(0)\n",
    "\n",
    "#         # Create heatmap\n",
    "#         heatmap = go.Heatmap(\n",
    "#             z=pivot_data.values,\n",
    "#             x=pivot_data.columns,\n",
    "#             y=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n",
    "#             colorscale='Viridis',\n",
    "#             showscale=(i==0),  # Only show colorbar for first heatmap\n",
    "#         )\n",
    "\n",
    "#         fig.add_trace(heatmap, row=i+1, col=1)\n",
    "\n",
    "#         # Update axes\n",
    "#         fig.update_xaxes(title_text=\"Hour of Day\" if i==n_sensors-1 else \"\", row=i+1, col=1)\n",
    "#         fig.update_yaxes(title_text=\"Day of Week\", row=i+1, col=1)\n",
    "\n",
    "#     # Update layout\n",
    "#     fig.update_layout(\n",
    "#         height=250*n_sensors,\n",
    "#         title_text=\"Daily Traffic Patterns Across Sensors\"\n",
    "#     )\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Function to create all interactive visualizations\n",
    "# def create_interactive_visualizations(data_file='test_data_1yr.pkl', window_size=24):\n",
    "#     \"\"\"Create and return a list of interactive visualizations for time window analysis\"\"\"\n",
    "#     # Load the data\n",
    "#     time_series_dict = load_data(data_file)\n",
    "\n",
    "#     # Create visualizations\n",
    "#     visualizations = []\n",
    "\n",
    "#     # 1. Data availability heatmap\n",
    "#     viz1 = interactive_data_availability(time_series_dict)\n",
    "#     visualizations.append(('data_availability', viz1))\n",
    "\n",
    "#     # 2. Window dashboard for top sensors\n",
    "#     viz2 = interactive_window_dashboard(time_series_dict, window_size=window_size)\n",
    "#     visualizations.append(('window_dashboard', viz2))\n",
    "\n",
    "#     # 3. Window counts\n",
    "#     viz3 = interactive_window_counts(time_series_dict, window_size=window_size)\n",
    "#     visualizations.append(('window_counts', viz3))\n",
    "\n",
    "#     # 4. PCA of windows\n",
    "#     viz4 = visualize_window_pca(time_series_dict, window_size=window_size)\n",
    "#     visualizations.append(('window_pca', viz4))\n",
    "\n",
    "#     # 5. Daily patterns heatmap\n",
    "#     viz5 = visualize_daily_patterns(time_series_dict)\n",
    "#     visualizations.append(('daily_patterns', viz5))\n",
    "\n",
    "#     return visualizations\n",
    "\n",
    "# # Create a comprehensive dashboard combining multiple visualizations\n",
    "# def create_sensor_window_dashboard(data_file='test_data_1yr.pkl', window_size=24):\n",
    "#     \"\"\"Create a comprehensive dashboard for analyzing sensor time windows\"\"\"\n",
    "#     # Load the data\n",
    "#     time_series_dict = load_data(data_file)\n",
    "\n",
    "#     # Identify sensors with most data points for individual analysis\n",
    "#     sensor_data_counts = {sensor_id: len(series) for sensor_id, series in time_series_dict.items()}\n",
    "#     top_sensor = max(sensor_data_counts, key=sensor_data_counts.get)\n",
    "\n",
    "#     # Create a multi-page dashboard using HTML and Plotly\n",
    "#     from plotly.io import to_html\n",
    "#     import plotly.io as pio\n",
    "\n",
    "#     # Set theme\n",
    "#     pio.templates.default = \"plotly_white\"\n",
    "\n",
    "#     # Create individual visualizations\n",
    "#     data_avail_fig = interactive_data_availability(time_series_dict)\n",
    "#     top_sensor_fig = interactive_sensor_windows(time_series_dict, top_sensor, window_size)\n",
    "#     window_counts_fig = interactive_window_counts(time_series_dict, window_size)\n",
    "#     daily_patterns_fig = visualize_daily_patterns(time_series_dict, n_sensors=4)\n",
    "\n",
    "#     # Try to create PCA visualization if possible\n",
    "#     try:\n",
    "#         pca_fig = visualize_window_pca(time_series_dict, window_size)\n",
    "#     except:\n",
    "#         pca_fig = None\n",
    "\n",
    "#     # Combine into HTML\n",
    "#     html_content = f\"\"\"\n",
    "#     <!DOCTYPE html>\n",
    "#     <html>\n",
    "#     <head>\n",
    "#         <title>Sensor Window Analysis Dashboard</title>\n",
    "#         <style>\n",
    "#             body {{\n",
    "#                 font-family: Arial, sans-serif;\n",
    "#                 margin: 0;\n",
    "#                 padding: 20px;\n",
    "#                 background-color: #f5f5f5;\n",
    "#             }}\n",
    "#             .dashboard-container {{\n",
    "#                 max-width: 1200px;\n",
    "#                 margin: 0 auto;\n",
    "#                 background-color: white;\n",
    "#                 border-radius: 8px;\n",
    "#                 overflow: hidden;\n",
    "#                 box-shadow: 0 0 10px rgba(0,0,0,0.1);\n",
    "#             }}\n",
    "#             .dashboard-header {{\n",
    "#                 background-color: #4C78A8;\n",
    "#                 color: white;\n",
    "#                 padding: 20px;\n",
    "#                 text-align: center;\n",
    "#             }}\n",
    "#             .dashboard-section {{\n",
    "#                 padding: 20px;\n",
    "#                 margin-bottom: 20px;\n",
    "#                 border-bottom: 1px solid #eee;\n",
    "#             }}\n",
    "#             h1 {{\n",
    "#                 margin: 0;\n",
    "#             }}\n",
    "#             h2 {{\n",
    "#                 color: #2C3E50;\n",
    "#                 margin-top: 0;\n",
    "#             }}\n",
    "#             .viz-container {{\n",
    "#                 margin-top: 20px;\n",
    "#             }}\n",
    "#         </style>\n",
    "#     </head>\n",
    "#     <body>\n",
    "#         <div class=\"dashboard-container\">\n",
    "#             <div class=\"dashboard-header\">\n",
    "#                 <h1>Sensor Time Window Analysis Dashboard</h1>\n",
    "#                 <p>Window Size: {window_size} time steps</p>\n",
    "#             </div>\n",
    "\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>Data Availability Overview</h2>\n",
    "#                 <p>This heatmap shows when data is available across all sensors. Darker blue indicates data availability.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(data_avail_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>Time Windows for Top Sensor (ID: {top_sensor})</h2>\n",
    "#                 <p>This visualization shows the raw data for the sensor with the most data points, highlighting continuous segments and example windows.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(top_sensor_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>Window Count Distribution</h2>\n",
    "#                 <p>This bar chart shows the number of available windows for each sensor.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(window_counts_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>Daily Traffic Patterns</h2>\n",
    "#                 <p>These heatmaps show the average traffic patterns by hour of day and day of week for top sensors.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(daily_patterns_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Add PCA visualization if available\n",
    "#     if pca_fig is not None:\n",
    "#         html_content += f\"\"\"\n",
    "#             <div class=\"dashboard-section\">\n",
    "#                 <h2>PCA of Sensor Windows</h2>\n",
    "#                 <p>This scatter plot shows a 2D representation of the window patterns across sensors using Principal Component Analysis.</p>\n",
    "#                 <div class=\"viz-container\">\n",
    "#                     {to_html(pca_fig, include_plotlyjs='cdn', full_html=False)}\n",
    "#                 </div>\n",
    "#             </div>\n",
    "#         \"\"\"\n",
    "\n",
    "#     # Close HTML\n",
    "#     html_content += \"\"\"\n",
    "#         </div>\n",
    "#     </body>\n",
    "#     </html>\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Return the HTML content\n",
    "#     return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Or create a complete dashboard\n",
    "# dashboard_html = create_sensor_window_dashboard(data_file='../test_data_1yr.pkl', window_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the HTML to a file\n",
    "# with open('sensor_dashboard.html', 'w') as f:\n",
    "#     f.write(dashboard_html)\n",
    "\n",
    "# print(\"Dashboard saved to sensor_dashboard.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
